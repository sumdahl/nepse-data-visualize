name: Daily Scrape NEPSE Data
on:
  schedule:
    - cron: "15 11 * * 0-4"
  workflow_dispatch:
jobs:
  scrape:
    runs-on: ubuntu-22.04
    env:
      PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: true
      PUPPETEER_EXECUTABLE_PATH: /usr/bin/chromium-browser
    steps:
      - uses: actions/checkout@v4

      - uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest

      - name: Cache Bun dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.bun
            node_modules
          key: ${{ runner.os }}-bun-${{ hashFiles('bun.lockb') }}
          restore-keys: |
            ${{ runner.os }}-bun-

      - name: Install dependencies
        run: |
          echo " Installing dependencies..."
          bun install --frozen-lockfile
          echo " Dependencies installed"

      - name: Run scraper
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          PUPPETEER_EXECUTABLE_PATH: /usr/bin/google-chrome
        run: |
          echo " Starting NEPSE scraper with Xvfb..."
          echo " Run time: $(date '+%Y-%m-%d %H:%M:%S %Z')"
          xvfb-run --auto-servernum --server-args="-screen 0 1920x1080x24" bun run src/scripts/scrape.ts
          echo " Scraper completed successfully!"

      - name: Job summary
        if: always()
        run: |
          echo "## Scrape Job Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Time:** $(date '+%Y-%m-%d %H:%M:%S %Z')" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Runner:** ${{ runner.os }}" >> $GITHUB_STEP_SUMMARY

