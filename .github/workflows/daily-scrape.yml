name: Daily Scrape NEPSE Data
on:
  schedule:
    - cron: "15 11 * * 0-4"
  workflow_dispatch:
jobs:
  scrape:
    runs-on: ubuntu-22.04
    env:
      PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: true
      PUPPETEER_EXECUTABLE_PATH: /usr/bin/chromium-browser
    steps:
      - uses: actions/checkout@v4

      - uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest

      - name: Cache Bun dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.bun
            node_modules
          key: ${{ runner.os }}-bun-${{ hashFiles('bun.lockb') }}
          restore-keys: |
            ${{ runner.os }}-bun-

      - name: Install Google Chrome and Xvfb
        run: |
          echo "Installing Google Chrome and Xvfb..."
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable xvfb
          google-chrome --version

      - name: Install dependencies
        run: |
          echo "Installing dependencies..."
          bun install --frozen-lockfile
          echo "Dependencies installed"

      - name: Run scraper
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          PUPPETEER_EXECUTABLE_PATH: /usr/bin/google-chrome
        run: |
          echo "Starting NEPSE scraper with Xvfb..."
          echo "Run time: $(date '+%Y-%m-%d %H:%M:%S %Z')"
          xvfb-run --auto-servernum --server-args="-screen 0 1920x1080x24" bun run src/scripts/scrape.ts
          echo "Scraper completed successfully!"

      - name: Push daily data to data repo
        env:
          DATA_REPO_TOKEN: ${{ secrets.DATA_REPO_TOKEN }}
        run: |
          set -euo pipefail
          if [ -z "${DATA_REPO_TOKEN}" ]; then
            echo "DATA_REPO_TOKEN is not set. Skipping data repo push."
            exit 0
          fi

          DATE_NPT="$(TZ=Asia/Kathmandu date +%F)"
          DATA_REPO="sumdahl/nepse-data-visualize"
          TMP_DIR="$(mktemp -d)"

          git clone "https://x-access-token:${DATA_REPO_TOKEN}@github.com/${DATA_REPO}.git" "${TMP_DIR}"
          mkdir -p "${TMP_DIR}/data"
          ls -l scraped_data.json
          cp scraped_data.json "${TMP_DIR}/data/${DATE_NPT}.json"

          cd "${TMP_DIR}"
          git config user.name "nepse-scrape-bot"
          git config user.email "nepse-scrape-bot@users.noreply.github.com"

          # Force-add in case data/ or *.json is ignored in the data repo.
          git add -f "data/${DATE_NPT}.json"
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "Add NEPSE scrape for ${DATE_NPT}"
          git push

      - name: Job summary
        if: always()
        run: |
          echo "## Scrape Job Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Time:** $(date '+%Y-%m-%d %H:%M:%S %Z')" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Runner:** ${{ runner.os }}" >> $GITHUB_STEP_SUMMARY
